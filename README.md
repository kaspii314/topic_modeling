# Topic Modeling: LDA vs. BERTopic

<img src="https://github.com/kaspii314/topic_modeling/blob/main/assets/bertopic.png">

[Topic Modeling Notebook](https://github.com/kaspii314/topic_modeling/blob/main/topic_modeling.ipynb)

Topic modeling is a Natural Language Processing (NLP) technique for discovering topics in a collection of documents, allowing you to see hidden structure in your text data. **Latent Dirichlet Allocation** (LDA), which was first presented in 2003 by David Blei, Andrew Ng and Michael I. Jordan, long reigned as the premier topic modeling method. However, **[BERTopic](https://maartengr.github.io/BERTopic/index.html)** by Maarten Grootendorst burst on the scene in 2022, leveraging recent advancements in large language models. In this sample project, we will focus less on the mathematics behind these methods and more on practical differences between LDA and BERTopic and the basics of how to make topic models.
